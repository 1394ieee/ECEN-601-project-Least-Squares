{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8. Repeat the above problem (solving only via the normal equations) for all pairs of digits. For each pair of digits, report the classification error rates for the training and testing sets. The error rates can be formatted nicely into a triangular matrix. For storage and display efficiency, store the testing error in the lower triangle and the training error in the upper triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as math\n",
    "import numpy as np\n",
    "import sympy as sy\n",
    "from sympy import series, Symbol\n",
    "from sympy.functions import sin, cos, exp\n",
    "from sympy.plotting import plot\n",
    "from sympy import lambdify\n",
    "from numpy import linspace\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy.linalg as la\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 feature  label\n",
       "0      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1\n",
       "1      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0\n",
       "2      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1\n",
       "3      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      4\n",
       "4      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0\n",
       "...                                                  ...    ...\n",
       "41995  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0\n",
       "41996  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1\n",
       "41997  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      7\n",
       "41998  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      6\n",
       "41999  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      9\n",
       "\n",
       "[42000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### loads the MNIST training data and plots the first 30 images.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Read MNIST csv file into dataframe\n",
    "df = pd.read_csv('mnist_train.csv')\n",
    "#df2 = pd.DataFrame(-255*np.ones(len(df.pixel1)),columns=list('a'))\n",
    "\n",
    "# to insert -1 prepend\n",
    "df.insert(1, \"a\", -1) \n",
    "# Merge pixels into feature column and keep only feature\n",
    "#axis 1 apply function to each row\n",
    "df ['feature'] = df.apply(lambda row: row.values [1 :], axis =1)\n",
    "df = df[['feature','label']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cer=[]\n",
    "Confusion_Matrix=[]\n",
    "S=[]\n",
    "Up=[]\n",
    "X=[]\n",
    "\n",
    "#PP=[]\n",
    "for i in range(1,10):#0,0+i\n",
    "    f0=df.loc[lambda df: df['label'] == 0, :]\n",
    "    train0, test0 =train_test_split(f0, train_size = 0.5)\n",
    "    train0_label=train0.label\n",
    "    train0_feature=train0.feature\n",
    "    test0_label=test0.label\n",
    "    test0_feature=test0.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test0_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train0_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test0_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train0_label, traini_label])\n",
    "    A=np.vstack(train_feature)\n",
    "    Y=np.vstack(train_label)\n",
    "    #soln=np.linalg.lstsq(A, Y,rcond=None)[0]\n",
    "    #S.append(soln)\n",
    "    \n",
    "    c=np.where(Y == 0, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    \n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(train_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x < 0.5:\n",
    "                return i\n",
    "            else:\n",
    "                return 0\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 0\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    Ccer=np.count_nonzero(np.array(TrainOutput)-np.array(TrainClass))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(U))   # D is just the diagonal of U\n",
    "    U /= np.diag(U)[:, None]  # Normalize rows of U\n",
    "    Up.append(U)\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "#print(cer)\n",
    "#print(S)\n",
    "#print (Confusion_Matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,10):#1,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 1, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    A=np.vstack(train_feature)\n",
    "    Y=np.vstack(train_label)\n",
    "    \n",
    "    c=np.where(Y == 1, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    \n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(train_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 1\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 1\n",
    "            return x\n",
    "    \n",
    "    #soln=np.linalg.lstsq(A, Y,rcond=None)[0]\n",
    "    #S.append(soln)\n",
    "    \n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(U))   # D is just the diagonal of U\n",
    "    U /= np.diag(U)[:, None]  # Normalize rows of U\n",
    "    Up.append(U)\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "#print(cer)\n",
    "#print (Confusion_Matrix)\n",
    "for i in range(3,10):#2,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 2, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    A=np.vstack(train_feature)\n",
    "    Y=np.vstack(train_label)\n",
    "    \n",
    "    c=np.where(Y == 2, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    \n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(train_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 2\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 2\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(U))   # D is just the diagonal of U\n",
    "    U /= np.diag(U)[:, None]  # Normalize rows of U\n",
    "    Up.append(U)\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "#print(cer)\n",
    "#print (Confusion_Matrix)\n",
    "\n",
    "for i in range(4,10):#3,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 3, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    A=np.vstack(train_feature)\n",
    "    Y=np.vstack(train_label)\n",
    "      \n",
    "    c=np.where(Y == 3, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    \n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(train_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 3\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 3\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(U))   # D is just the diagonal of U\n",
    "    U /= np.diag(U)[:, None]  # Normalize rows of U\n",
    "    Up.append(U)\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "#print(cer)\n",
    "#print (Confusion_Matrix)\n",
    "\n",
    "for i in range(5,10):#4,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 4, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    \n",
    "    A=np.vstack(train_feature)\n",
    "    Y=np.vstack(train_label)\n",
    "    c=np.where(Y == 4, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(train_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 4\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 4\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(U))   # D is just the diagonal of U\n",
    "    U /= np.diag(U)[:, None]  # Normalize rows of U\n",
    "    Up.append(U)\n",
    "    \n",
    "for i in range(6,10):#5,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 5, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    \n",
    "    A=np.vstack(train_feature)\n",
    "    Y=np.vstack(train_label)\n",
    "    c=np.where(Y == 5, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(train_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 5\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 5\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(U))   # D is just the diagonal of U\n",
    "    U /= np.diag(U)[:, None]  # Normalize rows of U\n",
    "    Up.append(U)\n",
    "    \n",
    "for i in range(7,10):#6,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 6, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    " \n",
    "    A=np.vstack(train_feature)\n",
    "    Y=np.vstack(train_label)\n",
    "    c=np.where(Y == 6, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(train_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 6\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 6\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(U))   # D is just the diagonal of U\n",
    "    U /= np.diag(U)[:, None]  # Normalize rows of U\n",
    "    Up.append(U)\n",
    "for i in range(8,10):#7,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 7, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    \n",
    "    A=np.vstack(train_feature)\n",
    "    Y=np.vstack(train_label)\n",
    "    c=np.where(Y == 7, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(train_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 7\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 7\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(U))   # D is just the diagonal of U\n",
    "    U /= np.diag(U)[:, None]  # Normalize rows of U\n",
    "    Up.append(U)\n",
    "for i in range(9,10):#8,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 8, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    \n",
    "    \n",
    "    A=np.vstack(train_feature)\n",
    "    Y=np.vstack(train_label)\n",
    "    c=np.where(Y == 8, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(train_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 8\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 8\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(U))   # D is just the diagonal of U\n",
    "    U /= np.diag(U)[:, None]  # Normalize rows of U\n",
    "    Up.append(U)\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "#print(cer)\n",
    "#print(S)\n",
    "rate= np.array(cer)/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification error rate is [0.00387879 0.00678788 0.00387879 0.00290909 0.008      0.00727273\n",
      " 0.00145455 0.00654545 0.00290909 0.01212121 0.00848485 0.00218182\n",
      " 0.00557576 0.00169697 0.00509091 0.01672727 0.00290909 0.02351515\n",
      " 0.00993939 0.01309091 0.01018182 0.01018182 0.01915152 0.00533333\n",
      " 0.00315152 0.03030303 0.00290909 0.00969697 0.02375758 0.01260606\n",
      " 0.00484848 0.00436364 0.00848485 0.00509091 0.02012121 0.01478788\n",
      " 0.00290909 0.0230303  0.00751515 0.00024242 0.00945455 0.00121212\n",
      " 0.00678788 0.02715152 0.01115152]\n"
     ]
    }
   ],
   "source": [
    "#Train Set error rate and confusion_matrix in upper traingle\n",
    "print(\"The classification error rate is\",rate)\n",
    "\n",
    "T8_cer_Test = pd.DataFrame(rate)\n",
    "T8_cer_Test.to_csv('T8_cer_Train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predicted     0     1\n",
      "Actual               \n",
      "0          2060     6\n",
      "1            10  2332, Predicted     0     2\n",
      "Actual               \n",
      "0          2055    11\n",
      "2            17  2071, Predicted     0     3\n",
      "Actual               \n",
      "0          2057     9\n",
      "3             7  2168, Predicted     0     4\n",
      "Actual               \n",
      "0          2056    10\n",
      "4             2  2034, Predicted     0     5\n",
      "Actual               \n",
      "0          2045    21\n",
      "5            12  1885, Predicted     0     6\n",
      "Actual               \n",
      "0          2050    16\n",
      "6            14  2054, Predicted     0     7\n",
      "Actual               \n",
      "0          2061     5\n",
      "7             1  2199, Predicted     0     8\n",
      "Actual               \n",
      "0          2050    16\n",
      "8            11  2020, Predicted     0     9\n",
      "Actual               \n",
      "0          2061     5\n",
      "9             7  2087, Predicted     1     2\n",
      "Actual               \n",
      "1          2318    24\n",
      "2            26  2062, Predicted     1     3\n",
      "Actual               \n",
      "1          2323    19\n",
      "3            16  2159, Predicted     1     4\n",
      "Actual               \n",
      "1          2338     4\n",
      "4             5  2031, Predicted     1     5\n",
      "Actual               \n",
      "1          2330    12\n",
      "5            11  1886, Predicted     1     6\n",
      "Actual               \n",
      "1          2339     3\n",
      "6             4  2064, Predicted     1     7\n",
      "Actual               \n",
      "1          2335     7\n",
      "7            14  2186, Predicted     1     8\n",
      "Actual               \n",
      "1          2324    18\n",
      "8            51  1980, Predicted     1     9\n",
      "Actual               \n",
      "1          2335     7\n",
      "9             5  2089, Predicted     2     3\n",
      "Actual               \n",
      "2          2047    41\n",
      "3            56  2119, Predicted     2     4\n",
      "Actual               \n",
      "2          2058    30\n",
      "4            11  2025, Predicted     2     5\n",
      "Actual               \n",
      "2          2062    26\n",
      "5            28  1869, Predicted     2     6\n",
      "Actual               \n",
      "2          2060    28\n",
      "6            14  2054, Predicted     2     7\n",
      "Actual               \n",
      "2          2065    23\n",
      "7            19  2181, Predicted     2     8\n",
      "Actual               \n",
      "2          2035    53\n",
      "8            26  2005, Predicted     2     9\n",
      "Actual               \n",
      "2          2075    13\n",
      "9             9  2085, Predicted     3     4\n",
      "Actual               \n",
      "3          2163    12\n",
      "4             1  2035, Predicted     3     5\n",
      "Actual               \n",
      "3          2112    63\n",
      "5            62  1835, Predicted     3     6\n",
      "Actual               \n",
      "3          2166     9\n",
      "6             3  2065, Predicted     3     7\n",
      "Actual               \n",
      "3          2148    27\n",
      "7            13  2187, Predicted     3     8\n",
      "Actual               \n",
      "3          2116    59\n",
      "8            39  1992, Predicted     3     9\n",
      "Actual               \n",
      "3          2156    19\n",
      "9            33  2061, Predicted     4     5\n",
      "Actual               \n",
      "4          2024    12\n",
      "5             8  1889, Predicted     4     6\n",
      "Actual               \n",
      "4          2029     7\n",
      "6            11  2057, Predicted     4     7\n",
      "Actual               \n",
      "4          2030     6\n",
      "7            29  2171, Predicted     4     8\n",
      "Actual               \n",
      "4          2030     6\n",
      "8            15  2016, Predicted     4     9\n",
      "Actual               \n",
      "4          1989    47\n",
      "9            36  2058, Predicted     5     6\n",
      "Actual               \n",
      "5          1860    37\n",
      "6            24  2044, Predicted     5     7\n",
      "Actual               \n",
      "5          1890     7\n",
      "7             5  2195, Predicted     5     8\n",
      "Actual               \n",
      "5          1861    36\n",
      "8            59  1972, Predicted     5     9\n",
      "Actual               \n",
      "5          1892     5\n",
      "9            26  2068, Predicted     6     7\n",
      "Actual               \n",
      "6          2068     0\n",
      "7             1  2199, Predicted     6     8\n",
      "Actual               \n",
      "6          2040    28\n",
      "8            11  2020, Predicted     6     9\n",
      "Actual               \n",
      "6          2066     2\n",
      "9             3  2091, Predicted     7     8\n",
      "Actual               \n",
      "7          2186    14\n",
      "8            14  2017, Predicted     7     9\n",
      "Actual               \n",
      "7          2131    69\n",
      "9            43  2051, Predicted     8     9\n",
      "Actual               \n",
      "8          2010    21\n",
      "9            25  2069]\n"
     ]
    }
   ],
   "source": [
    "print(Confusion_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix in upper traingle way for train set is  [array([[1.        , 0.00291262],\n",
      "       [0.        , 1.        ]]), array([[1.       , 0.0053528],\n",
      "       [0.       , 1.       ]]), array([[1.       , 0.0043753],\n",
      "       [0.       , 1.       ]]), array([[1.        , 0.00486381],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.01026895],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00780488],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00242601],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00780488],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00242601],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.01035375],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00817908],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00171086],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00515021],\n",
      "       [0.        , 1.        ]]), array([[1.       , 0.0012826],\n",
      "       [0.       , 1.       ]]), array([[1.        , 0.00299786],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00774527],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00299786],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.02002931],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.01457726],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.01260912],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.01359223],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.01113801],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.02604423],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00626506],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00554785],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.02982955],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00415512],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.01256983],\n",
      "       [0.        , 1.        ]]), array([[1.       , 0.0278828],\n",
      "       [0.       , 1.       ]]), array([[1.        , 0.00881262],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00592885],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00344998],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00295567],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00295567],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.02362996],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.01989247],\n",
      "       [0.        , 1.        ]]), array([[1.       , 0.0037037],\n",
      "       [0.       , 1.       ]]), array([[1.        , 0.01934444],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.00264271],\n",
      "       [0.        , 1.        ]]), array([[1., 0.],\n",
      "       [0., 1.]]), array([[1.        , 0.01372549],\n",
      "       [0.        , 1.        ]]), array([[1.00000000e+00, 9.68054211e-04],\n",
      "       [0.00000000e+00, 1.00000000e+00]]), array([[1.        , 0.00640439],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.03237916],\n",
      "       [0.        , 1.        ]]), array([[1.        , 0.01044776],\n",
      "       [0.        , 1.        ]])]\n"
     ]
    }
   ],
   "source": [
    "#Train set confusion_matrix in upper traingle\n",
    "print('The Confusion Matrix in upper traingle way for train set is ',Up)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
