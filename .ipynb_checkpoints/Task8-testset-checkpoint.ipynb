{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8. Repeat the above problem (solving only via the normal equations) for all pairs of digits. For each pair of digits, report the classification error rates for the training and testing sets. The error rates can be formatted nicely into a triangular matrix. For storage and display efficiency, store the testing error in the lower triangle and the training error in the upper triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as math\n",
    "import numpy as np\n",
    "import sympy as sy\n",
    "from sympy import series, Symbol\n",
    "from sympy.functions import sin, cos, exp\n",
    "from sympy.plotting import plot\n",
    "from sympy import lambdify\n",
    "from numpy import linspace\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy.linalg as la\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 feature  label\n",
       "0      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1\n",
       "1      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0\n",
       "2      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1\n",
       "3      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      4\n",
       "4      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0\n",
       "...                                                  ...    ...\n",
       "41995  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0\n",
       "41996  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1\n",
       "41997  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      7\n",
       "41998  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      6\n",
       "41999  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      9\n",
       "\n",
       "[42000 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### loads the MNIST training data and plots the first 30 images.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Read MNIST csv file into dataframe\n",
    "df = pd.read_csv('mnist_train.csv')\n",
    "#df2 = pd.DataFrame(-255*np.ones(len(df.pixel1)),columns=list('a'))\n",
    "\n",
    "# to insert -1 prepend\n",
    "df.insert(1, \"a\", -1) \n",
    "# Merge pixels into feature column and keep only feature\n",
    "#axis 1 apply function to each row\n",
    "df ['feature'] = df.apply(lambda row: row.values [1 :], axis =1)\n",
    "df = df[['feature','label']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cer=[]\n",
    "Confusion_Matrix=[]\n",
    "S=[]\n",
    "Ld=[]\n",
    "X=[]\n",
    "\n",
    "#PP=[]\n",
    "for i in range(1,10):#0,0+i\n",
    "    f0=df.loc[lambda df: df['label'] == 0, :]\n",
    "    train0, test0 =train_test_split(f0, train_size = 0.5)\n",
    "    train0_label=train0.label\n",
    "    train0_feature=train0.feature\n",
    "    test0_label=test0.label\n",
    "    test0_feature=test0.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test0_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train0_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test0_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train0_label, traini_label])\n",
    "    A=np.vstack(test_feature)\n",
    "    Y=np.vstack(test_label)\n",
    "    #soln=np.linalg.lstsq(A, Y,rcond=None)[0]\n",
    "    #S.append(soln)\n",
    "    \n",
    "    c=np.where(Y == 0, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    \n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(test_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x < 0.5:\n",
    "                return i\n",
    "            else:\n",
    "                return 0\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 0\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    Ccer=np.count_nonzero(np.array(TrainOutput)-np.array(TrainClass))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(L))   # D is just the diagonal of U\n",
    "    L /= np.diag(L)[:, None]  # Normalize rows of U\n",
    "    Ld.append(L)\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "#print(cer)\n",
    "#print(S)\n",
    "#print (Confusion_Matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,10):#1,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 1, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    A=np.vstack(test_feature)\n",
    "    Y=np.vstack(test_label)\n",
    "    \n",
    "    c=np.where(Y == 1, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    \n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(test_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 1\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 1\n",
    "            return x\n",
    "    \n",
    "    #soln=np.linalg.lstsq(A, Y,rcond=None)[0]\n",
    "    #S.append(soln)\n",
    "    \n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(L))   # D is just the diagonal of U\n",
    "    L /= np.diag(L)[:, None]  # Normalize rows of U\n",
    "    Ld.append(L)\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "#print(cer)\n",
    "#print (Confusion_Matrix)\n",
    "for i in range(3,10):#2,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 2, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    A=np.vstack(test_feature)\n",
    "    Y=np.vstack(test_label)\n",
    "    \n",
    "    c=np.where(Y == 2, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    \n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(test_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 2\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 2\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(L))   # D is just the diagonal of U\n",
    "    L /= np.diag(L)[:, None]  # Normalize rows of U\n",
    "    Ld.append(L)\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "#print(cer)\n",
    "#print (Confusion_Matrix)\n",
    "\n",
    "for i in range(4,10):#3,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 3, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    A=np.vstack(test_feature)\n",
    "    Y=np.vstack(test_label)\n",
    "      \n",
    "    c=np.where(Y == 3, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    \n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(test_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 3\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 3\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(L))   # D is just the diagonal of U\n",
    "    L /= np.diag(L)[:, None]  # Normalize rows of U\n",
    "    Ld.append(L)\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "#print(cer)\n",
    "#print (Confusion_Matrix)\n",
    "\n",
    "for i in range(5,10):#4,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 4, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    \n",
    "    A=np.vstack(test_feature)\n",
    "    Y=np.vstack(test_label)\n",
    "    c=np.where(Y == 4, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(test_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 4\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 4\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(L))   # D is just the diagonal of U\n",
    "    L /= np.diag(L)[:, None]  # Normalize rows of U\n",
    "    Ld.append(L)\n",
    "    \n",
    "for i in range(6,10):#5,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 5, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    \n",
    "    A=np.vstack(test_feature)\n",
    "    Y=np.vstack(test_label)\n",
    "    c=np.where(Y == 5, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(test_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 5\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 5\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(L))   # D is just the diagonal of U\n",
    "    L /= np.diag(L)[:, None]  # Normalize rows of U\n",
    "    Ld.append(L)\n",
    "    \n",
    "for i in range(7,10):#6,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 6, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    " \n",
    "    A=np.vstack(test_feature)\n",
    "    Y=np.vstack(test_label)\n",
    "    c=np.where(Y == 6, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(test_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 6\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 6\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(L))   # D is just the diagonal of U\n",
    "    L /= np.diag(L)[:, None]  # Normalize rows of U\n",
    "    Ld.append(L)\n",
    "for i in range(8,10):#7,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 7, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    \n",
    "    A=np.vstack(test_feature)\n",
    "    Y=np.vstack(test_label)\n",
    "    c=np.where(Y == 7, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(test_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 7\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 7\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(L))   # D is just the diagonal of U\n",
    "    L /= np.diag(L)[:, None]  # Normalize rows of U\n",
    "    Ld.append(L)\n",
    "for i in range(9,10):#8,0+i\n",
    "    f1=df.loc[lambda df: df['label'] == 8, :]\n",
    "    train1, test1 =train_test_split(f1, train_size = 0.5)\n",
    "    train1_label=train1.label\n",
    "    train1_feature=train1.feature\n",
    "    test1_label=test1.label\n",
    "    test1_feature=test1.feature\n",
    "    fi=df.loc[lambda df: df['label'] == i, :]\n",
    "    traini, testi =train_test_split(fi, train_size = 0.5)\n",
    "    traini_label=traini.label\n",
    "    traini_feature=traini.feature\n",
    "    testi_label=testi.label\n",
    "    testi_feature=testi.feature\n",
    "    test_feature =np.hstack([np.array(test1_feature), np.array(testi_feature)])/255 \n",
    "    train_feature =np.hstack([train1_feature, traini_feature])/255\n",
    "    test_label =np.hstack([np.array(test1_label),np.array(testi_label)]) \n",
    "    train_label =np.hstack([train1_label, traini_label])\n",
    "    \n",
    "    \n",
    "    A=np.vstack(test_feature)\n",
    "    Y=np.vstack(test_label)\n",
    "    c=np.where(Y == 8, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "    l=len(A)\n",
    "    X=[]\n",
    "    for j in range(0,l):\n",
    "        p=np.dot(np.array(test_feature[j]),np.array(s))\n",
    "        X.append(p)\n",
    "        #X=np.array(X)\n",
    "        #print(X)\n",
    "        def LSclassifier(x):\n",
    "            if x >0.5 :\n",
    "                return 8\n",
    "            else:\n",
    "                return i\n",
    "            return x\n",
    "    TrainOutput=[LSclassifier(x) for x in X]\n",
    "    def Lclassifier(x):\n",
    "            if x == i:\n",
    "                return i\n",
    "            else:\n",
    "                return 8\n",
    "            return x\n",
    "    TrainClass=[Lclassifier(x) for x in Y]\n",
    "    \n",
    "    Ccer=np.count_nonzero(np.array(TrainClass)-np.array(TrainOutput))\n",
    "    cer.append(Ccer)\n",
    "    import pandas as pd\n",
    "    data = {'y_Actual':    np.array(TrainClass),\n",
    "        'y_Predicted': np.array(TrainOutput).T\n",
    "        }\n",
    "    dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    Confusion_Matrix.append(confusion_matrix)\n",
    "    import scipy.linalg as la\n",
    "    (P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "    D = np.diag(np.diag(L))   # D is just the diagonal of U\n",
    "    L /= np.diag(L)[:, None]  # Normalize rows of U\n",
    "    Ld.append(L)\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "#print(cer)\n",
    "#print(S)\n",
    "rate= np.array(cer)/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification error rate is [0.00436258 0.0063015  0.00339312 0.00169656 0.00581677 0.00678623\n",
      " 0.00169656 0.00605914 0.00315075 0.00920989 0.00799806 0.00218129\n",
      " 0.00508968 0.00193892 0.00678623 0.01720795 0.00266602 0.01672322\n",
      " 0.00872516 0.01284537 0.01163354 0.00945225 0.01769268 0.0077557\n",
      " 0.00436258 0.03005332 0.00290839 0.00848279 0.02496365 0.01260301\n",
      " 0.0063015  0.00339312 0.0070286  0.00412021 0.02399418 0.01381483\n",
      " 0.00339312 0.02302472 0.0077557  0.00024237 0.00872516 0.00096946\n",
      " 0.0063015  0.02520601 0.01211827]\n"
     ]
    }
   ],
   "source": [
    "#Train Set error rate and confusion_matrix in upper traingle\n",
    "print(\"The classification error rate is\",rate)\n",
    "\n",
    "T8_cer_Test = pd.DataFrame(rate)\n",
    "T8_cer_Test.to_csv('T8_cer_Test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predicted     0     1\n",
      "Actual               \n",
      "0          2061     5\n",
      "1            13  2329, Predicted     0     2\n",
      "Actual               \n",
      "0          2054    12\n",
      "2            14  2075, Predicted     0     3\n",
      "Actual               \n",
      "0          2059     7\n",
      "3             7  2169, Predicted     0     4\n",
      "Actual               \n",
      "0          2059     7\n",
      "4             0  2036, Predicted     0     5\n",
      "Actual               \n",
      "0          2047    19\n",
      "5             5  1893, Predicted     0     6\n",
      "Actual               \n",
      "0          2054    12\n",
      "6            16  2053, Predicted     0     7\n",
      "Actual               \n",
      "0          2062     4\n",
      "7             3  2198, Predicted     0     8\n",
      "Actual               \n",
      "0          2054    12\n",
      "8            13  2019, Predicted     0     9\n",
      "Actual               \n",
      "0          2063     3\n",
      "9            10  2084, Predicted     1     2\n",
      "Actual               \n",
      "1          2319    23\n",
      "2            15  2074, Predicted     1     3\n",
      "Actual               \n",
      "1          2327    15\n",
      "3            18  2158, Predicted     1     4\n",
      "Actual               \n",
      "1          2336     6\n",
      "4             3  2033, Predicted     1     5\n",
      "Actual               \n",
      "1          2331    11\n",
      "5            10  1888, Predicted     1     6\n",
      "Actual               \n",
      "1          2341     1\n",
      "6             7  2062, Predicted     1     7\n",
      "Actual               \n",
      "1          2335     7\n",
      "7            21  2180, Predicted     1     8\n",
      "Actual               \n",
      "1          2324    18\n",
      "8            53  1979, Predicted     1     9\n",
      "Actual               \n",
      "1          2337     5\n",
      "9             6  2088, Predicted     2     3\n",
      "Actual               \n",
      "2          2057    32\n",
      "3            37  2139, Predicted     2     4\n",
      "Actual               \n",
      "2          2062    27\n",
      "4             9  2027, Predicted     2     5\n",
      "Actual               \n",
      "2          2059    30\n",
      "5            23  1875, Predicted     2     6\n",
      "Actual               \n",
      "2          2054    35\n",
      "6            13  2056, Predicted     2     7\n",
      "Actual               \n",
      "2          2071    18\n",
      "7            21  2180, Predicted     2     8\n",
      "Actual               \n",
      "2          2044    45\n",
      "8            28  2004, Predicted     2     9\n",
      "Actual               \n",
      "2          2066    23\n",
      "9             9  2085, Predicted     3     4\n",
      "Actual               \n",
      "3          2163    13\n",
      "4             5  2031, Predicted     3     5\n",
      "Actual               \n",
      "3          2111    65\n",
      "5            59  1839, Predicted     3     6\n",
      "Actual               \n",
      "3          2165    11\n",
      "6             1  2068, Predicted     3     7\n",
      "Actual               \n",
      "3          2147    29\n",
      "7             6  2195, Predicted     3     8\n",
      "Actual               \n",
      "3          2117    59\n",
      "8            44  1988, Predicted     3     9\n",
      "Actual               \n",
      "3          2154    22\n",
      "9            30  2064, Predicted     4     5\n",
      "Actual               \n",
      "4          2021    15\n",
      "5            11  1887, Predicted     4     6\n",
      "Actual               \n",
      "4          2031     5\n",
      "6             9  2060, Predicted     4     7\n",
      "Actual               \n",
      "4          2026    10\n",
      "7            19  2182, Predicted     4     8\n",
      "Actual               \n",
      "4          2029     7\n",
      "8            10  2022, Predicted     4     9\n",
      "Actual               \n",
      "4          1980    56\n",
      "9            43  2051, Predicted     5     6\n",
      "Actual               \n",
      "5          1866    32\n",
      "6            25  2044, Predicted     5     7\n",
      "Actual               \n",
      "5          1891     7\n",
      "7             7  2194, Predicted     5     8\n",
      "Actual               \n",
      "5          1866    32\n",
      "8            63  1969, Predicted     5     9\n",
      "Actual               \n",
      "5          1887    11\n",
      "9            21  2073, Predicted     6     7\n",
      "Actual               \n",
      "6          2069     0\n",
      "7             1  2200, Predicted     6     8\n",
      "Actual               \n",
      "6          2047    22\n",
      "8            14  2018, Predicted     6     9\n",
      "Actual               \n",
      "6          2068     1\n",
      "9             3  2091, Predicted     7     8\n",
      "Actual               \n",
      "7          2187    14\n",
      "8            12  2020, Predicted     7     9\n",
      "Actual               \n",
      "7          2139    62\n",
      "9            42  2052, Predicted     8     9\n",
      "Actual               \n",
      "8          2008    24\n",
      "9            26  2068]\n"
     ]
    }
   ],
   "source": [
    "print(Confusion_Matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Confusion Matrix in lower traingle way for train set is  [array([[1.        , 0.        ],\n",
      "       [0.00630762, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00681597, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00339971, 1.        ]]), array([[1., 0.],\n",
      "       [0., 1.]]), array([[1.       , 0.       ],\n",
      "       [0.0024426, 1.       ]]), array([[1.        , 0.        ],\n",
      "       [0.00778968, 1.        ]]), array([[1.       , 0.       ],\n",
      "       [0.0014549, 1.       ]]), array([[1.        , 0.        ],\n",
      "       [0.00632911, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00484731, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00646831, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00773528, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00128425, 1.        ]]), array([[1.     , 0.     ],\n",
      "       [0.00429, 1.     ]]), array([[1.        , 0.        ],\n",
      "       [0.00299018, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00899358, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.02280551, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00256739, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.01798736, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00436469, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.01117047, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00632911, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.01014003, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.01369863, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00435624, 1.        ]]), array([[1.       , 0.       ],\n",
      "       [0.0023116, 1.       ]]), array([[1.        , 0.        ],\n",
      "       [0.02794884, 1.        ]]), array([[1.00000000e+00, 0.00000000e+00],\n",
      "       [4.61893764e-04, 1.00000000e+00]]), array([[1.       , 0.       ],\n",
      "       [0.0027946, 1.       ]]), array([[1.        , 0.        ],\n",
      "       [0.02078413, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.01392758, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00544285, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00443131, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00937808, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00492854, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.02171717, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.01339764, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00370175, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.03376206, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.01112878, 1.        ]]), array([[1.00000000e+00, 0.00000000e+00],\n",
      "       [4.83325278e-04, 1.00000000e+00]]), array([[1.        , 0.        ],\n",
      "       [0.00683928, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00145068, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.00548697, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.01963534, 1.        ]]), array([[1.        , 0.        ],\n",
      "       [0.01294821, 1.        ]])]\n"
     ]
    }
   ],
   "source": [
    "#Train set confusion_matrix in lower traingle\n",
    "print('The Confusion Matrix in lower traingle way for train set is ',Ld)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
