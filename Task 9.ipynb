{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9. \n",
    "But, what about a multi-class classifier for MNIST digits? For multi-class linear classification with d classes, one standard approach is to learn a linear mapping f : Rn → Rd where the “y”-value for the ith class is chosen to be the standard basis vector ei ∈ Rd. This is sometimes called one-hot encoding. Using the same A matrix as before and a matrix Y , defined by Yi,j = 1, if observation i in class j and Yi,j = 0 otherwise, we can solve for the coefficient matrix B ∈ Rn×d entries. The classifier maps a vector x to class i if the ith element of BTx is the largest element\n",
    "in the vector. Report both the overall classification error rate and confusion matrices for the both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as math\n",
    "import numpy as np\n",
    "import sympy as sy\n",
    "from sympy import series, Symbol\n",
    "from sympy.functions import sin, cos, exp\n",
    "from sympy.plotting import plot\n",
    "from sympy import lambdify\n",
    "from numpy import linspace\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 feature  label\n",
       "0      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1\n",
       "1      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0\n",
       "2      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1\n",
       "3      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      4\n",
       "4      [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0\n",
       "...                                                  ...    ...\n",
       "41995  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      0\n",
       "41996  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      1\n",
       "41997  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      7\n",
       "41998  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      6\n",
       "41999  [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...      9\n",
       "\n",
       "[42000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### loads the MNIST training data and plots the first 30 images.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Read MNIST csv file into dataframe\n",
    "df = pd.read_csv('mnist_train.csv')\n",
    "#df2 = pd.DataFrame(-255*np.ones(len(df.pixel1)),columns=list('a'))\n",
    "\n",
    "# to insert -1 prepend\n",
    "df.insert(1, \"a\", -1) \n",
    "# Merge pixels into feature column and keep only feature\n",
    "#axis 1 apply function to each row\n",
    "df ['feature'] = df.apply(lambda row: row.values [1 :], axis =1)\n",
    "df = df[['feature','label']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test =train_test_split(df, train_size = 0.5)\n",
    "train_label=train.label\n",
    "train_feature=train.feature\n",
    "test_label=test.label\n",
    "test_feature=test.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one vs all for train data\n",
    "A=np.vstack(train_feature)\n",
    "l=len(A)\n",
    "Y=np.hstack(train_label)\n",
    "#print(Y)\n",
    "# 0 and others\n",
    "S=[]\n",
    "for i in range (0,10):\n",
    "    c=np.where(Y == i, Y, -1)\n",
    "    c=np.where(c == -1, c, 0)\n",
    "    c=abs(np.invert(c))#+2\n",
    "    s=np.linalg.lstsq(A, c,rcond=None)[0]\n",
    "    S.append(s)\n",
    "#print(S)\n",
    "S=np.array(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification error rate is 0.1990952380952381\n",
      "Predicted     0     1     2     3     4    5     6     7     8     9\n",
      "Actual                                                              \n",
      "0          1849     0    14    18     3   12    23     0   137     3\n",
      "1             0  2067    11    22     0    2     5     0   261     1\n",
      "2            19    22  1613    80    13    2    87    13   215    19\n",
      "3             2     9    58  1808     2    6    10    21   223    40\n",
      "4             4    20    33    16  1453    9    18     3   272   237\n",
      "5            17     9    19   247     9  822    49    10   615    68\n",
      "6            26     3    25     2     7   15  1896     0    90     3\n",
      "7             8    32    23    46    25    2     4  1734    82   258\n",
      "8             6    27    15    47     2   17    12     3  1817    37\n",
      "9             6     3    10    32    26    2     0   112   165  1760\n",
      "[[ 1.00000000e+00  0.00000000e+00  7.57166036e-03  9.73499189e-03\n",
      "   1.62249865e-03  6.48999459e-03  1.24391563e-02  0.00000000e+00\n",
      "   7.40941049e-02  1.62249865e-03]\n",
      " [ 0.00000000e+00  1.00000000e+00  5.32172230e-03  1.06434446e-02\n",
      "   0.00000000e+00  9.67585873e-04  2.41896468e-03  0.00000000e+00\n",
      "   1.26269956e-01  4.83792937e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00  4.93451677e-02\n",
      "   8.04170547e-03  1.15046709e-03  5.37659445e-02  8.06082045e-03\n",
      "   1.30718154e-01  1.17554845e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "   8.48100343e-04  3.27510946e-03  3.78848627e-03  1.13754497e-02\n",
      "   1.18636513e-01  2.17788151e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  6.10622210e-03  1.10698903e-02  1.77212680e-03\n",
      "   1.81182176e-01  1.62653710e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  5.69159858e-02  8.57100295e-03\n",
      "   7.05748805e-01  7.42903131e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00 -1.81606765e-04\n",
      "   3.84262914e-02  2.42282656e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "   3.65926466e-02  1.45730780e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.89249707e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# compute C linear combinations of input point, one per classifier\n",
    "def model(x,w):\n",
    "    a = np.dot(x,w.T)+w.T[0]\n",
    "    return a.T\n",
    "# the fusion rule\n",
    "def fusion_rule(x,w):\n",
    "    return np.argmax(model(x,w))\n",
    "P=[]\n",
    "for i in range (0,len(A)):\n",
    "    cA=np.array(fusion_rule(A[i],S))\n",
    "    P.append(cA)\n",
    "P=np.array(P)\n",
    "CER=np.count_nonzero(P-Y)\n",
    "rate=np.array(CER)/l\n",
    "print(\"classification error rate is\",rate)\n",
    "\n",
    "\n",
    "#matrix\n",
    "import pandas as pd\n",
    "data = {'y_Actual':    np.array(Y),\n",
    "        'y_Predicted': np.array(P)\n",
    "        }\n",
    "dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)\n",
    "\n",
    "T9_Confusion_Matrix_Train = pd.DataFrame(confusion_matrix)\n",
    "T9_Confusion_Matrix_Train.to_csv('T9_Confusion_Matrix_Train.csv', index=False)\n",
    "\n",
    "import scipy.linalg as la\n",
    "(P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "#print(P)\n",
    "#print(L)\n",
    "#print(U)\n",
    "D = np.diag(np.diag(U))   # D is just the diagonal of U\n",
    "U /= np.diag(U)[:, None]  # Normalize rows of U\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "print(U)\n",
    "\n",
    "T9_U_Train = pd.DataFrame(U)\n",
    "T9_U_Train.to_csv('T9_UpperTraingle_Train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification error rate is 0.1990952380952381\n",
      "Predicted     0     1     2     3     4    5     6     7     8     9\n",
      "Actual                                                              \n",
      "0          1849     0    14    18     3   12    23     0   137     3\n",
      "1             0  2067    11    22     0    2     5     0   261     1\n",
      "2            19    22  1613    80    13    2    87    13   215    19\n",
      "3             2     9    58  1808     2    6    10    21   223    40\n",
      "4             4    20    33    16  1453    9    18     3   272   237\n",
      "5            17     9    19   247     9  822    49    10   615    68\n",
      "6            26     3    25     2     7   15  1896     0    90     3\n",
      "7             8    32    23    46    25    2     4  1734    82   258\n",
      "8             6    27    15    47     2   17    12     3  1817    37\n",
      "9             6     3    10    32    26    2     0   112   165  1760\n",
      "[[ 1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.02758248e-02  1.06434446e-02  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.08166577e-03  4.35413643e-03  3.59245724e-02  1.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 2.16333153e-03  9.67585873e-03  2.03773070e-02  7.82622991e-03\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 9.19415900e-03  4.35413643e-03  1.16716875e-02  1.36180805e-01\n",
      "   5.92859618e-03  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.40616549e-02  1.45137881e-03  1.53696108e-02  2.72479610e-04\n",
      "   4.65201798e-03  1.79743406e-02  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 4.32666306e-03  1.54813740e-02  1.41182986e-02  2.46301092e-02\n",
      "   1.70481988e-02  1.94163968e-03  1.09091437e-03  1.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 3.24499730e-03  1.30624093e-02  9.18368253e-03  2.54419470e-02\n",
      "   1.26123140e-03  2.04095858e-02  5.23696151e-03  1.27687530e-03\n",
      "   1.00000000e+00  0.00000000e+00]\n",
      " [ 3.24499730e-03  1.45137881e-03  6.16256226e-03  1.74065307e-02\n",
      "   1.78174349e-02  2.05330913e-03 -5.90338422e-04  6.43310134e-02\n",
      "   8.32245243e-02  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "## for test data\n",
    "A=np.vstack(test_feature)\n",
    "Y=np.hstack(test_label)\n",
    "P=[]\n",
    "for i in range (0,len(A)):\n",
    "    c=np.array(fusion_rule(A[i],S))\n",
    "    P.append(c)\n",
    "P=np.array(P)\n",
    "CER=np.count_nonzero(P-Y)\n",
    "rate=CER/l\n",
    "print(\"classification error rate is\",rate)\n",
    "#print(CER)\n",
    "#matrix\n",
    "import pandas as pd\n",
    "data = {'y_Actual':    np.array(Y),\n",
    "        'y_Predicted': np.array(P)\n",
    "        }\n",
    "dfm = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(dfm['y_Actual'], dfm['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)\n",
    "\n",
    "import scipy.linalg as la\n",
    "(P, L, U) = la.lu(np.array(confusion_matrix))\n",
    "\n",
    "D = np.diag(np.diag(L))   # D is just the diagonal of U\n",
    "L /= np.diag(L)[:, None]  # Normalize rows of U\n",
    "#print(P.dot(L.dot(D.dot(U))))    # Check\n",
    "print(L)\n",
    "\n",
    "T9_Confusion_Matrix_Test = pd.DataFrame(confusion_matrix)\n",
    "T9_Confusion_Matrix_Test.to_csv('T9_Confusion_Matrix_Test.csv', index=False)\n",
    "T9_LT_Test = pd.DataFrame(L)\n",
    "T9_LT_Test.to_csv('T9_LowerTraingle_Test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
